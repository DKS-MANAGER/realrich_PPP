{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c224b505",
   "metadata": {},
   "source": [
    "## Phase 1: Data Collection & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a093545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Conv1D, MaxPooling1D, Dropout\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def fetch_data(ticker='SI=F', period='20y'):\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    df = yf.Ticker(ticker).history(period=period)\n",
    "    return df\n",
    "\n",
    "# 1. Fetch Data\n",
    "df = fetch_data()\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "df['Close'].plot(title='Silver Price History (20y)', figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e903a5",
   "metadata": {},
   "source": [
    "## Phase 2: Exploratory Analysis & Visualization\n",
    "We check for stationarity using the Augmented Dickey-Fuller (ADF) test and visualize rolling statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries):\n",
    "    # Rolling statistics\n",
    "    rolmean = timeseries.rolling(window=12).mean()\n",
    "    rolstd = timeseries.rolling(window=12).std()\n",
    "\n",
    "    # Plot rolling statistics\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(timeseries, color='blue', label='Original')\n",
    "    plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    plt.plot(rolstd, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    # Dickey-Fuller Test\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "test_stationarity(df['Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f3c39",
   "metadata": {},
   "source": [
    "## Phase 3: ARIMA Baseline Model\n",
    "A simple ARIMA model to establish a baseline for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ba4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ARIMA on Close price\n",
    "# Note: For a real rigorous ARIMA, we'd grid search (p,d,q). Here we use a standard config.\n",
    "train_data, test_data = df['Close'][0:int(len(df)*0.8)], df['Close'][int(len(df)*0.8):]\n",
    "\n",
    "history = [x for x in train_data]\n",
    "predictions = []\n",
    "\n",
    "# Walk-forward validation for ARIMA (simplified for speed)\n",
    "print(\"Training ARIMA baseline (this may take a moment)...\")\n",
    "# We'll just forecast the test set in one go for speed in this demo, \n",
    "# or a small walk-forward loop.\n",
    "model = ARIMA(history, order=(5,1,0))\n",
    "model_fit = model.fit()\n",
    "output = model_fit.forecast(steps=len(test_data))\n",
    "predictions = output\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_data, predictions))\n",
    "print(f'ARIMA Baseline RMSE: {rmse:.4f}')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_data.index, test_data.values, label='Actual')\n",
    "plt.plot(test_data.index, predictions, color='red', label='ARIMA Forecast')\n",
    "plt.title('ARIMA Baseline Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f67b0",
   "metadata": {},
   "source": [
    "## Phase 4: Hybrid Deep Learning Model (CNN-LSTM-GRU)\n",
    "Implementing the advanced architecture to capture spatial and temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbfd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def build_hybrid_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(units=64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        GRU(units=64, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Preprocessing\n",
    "data = df[['Close']].values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "SEQ_LENGTH = 60\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "# Split\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train\n",
    "print(\"Training Hybrid Model...\")\n",
    "model = build_hybrid_model((X_train.shape[1], X_train.shape[2]))\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa49769a",
   "metadata": {},
   "source": [
    "## Phase 5 & 6: Validation & Risk Metrics\n",
    "Evaluating the model with standard metrics and visualizing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce48c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions_inv = scaler.inverse_transform(predictions)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_test_inv, predictions_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, predictions_inv))\n",
    "print(f\"Hybrid Model Test MAE: {mae:.4f}\")\n",
    "print(f\"Hybrid Model Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_inv, label='Actual Price')\n",
    "plt.plot(predictions_inv, label='Predicted Price')\n",
    "plt.title('Hybrid Model Predictions vs Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54374645",
   "metadata": {},
   "source": [
    "## Phase 7: Production Deployment & Forecasting\n",
    "Generating the 30-day forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_DAYS = 30\n",
    "last_sequence = scaled_data[-SEQ_LENGTH:]\n",
    "curr_seq = last_sequence.reshape((1, SEQ_LENGTH, 1))\n",
    "future_predictions = []\n",
    "\n",
    "for _ in range(FORECAST_DAYS):\n",
    "    pred = model.predict(curr_seq, verbose=0)\n",
    "    future_predictions.append(pred[0, 0])\n",
    "    pred_reshaped = pred.reshape((1, 1, 1))\n",
    "    curr_seq = np.append(curr_seq[:, 1:, :], pred_reshaped, axis=1)\n",
    "\n",
    "future_predictions_inv = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "\n",
    "# Create DataFrame\n",
    "last_date = df.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=FORECAST_DAYS, freq='B')\n",
    "forecast_df = pd.DataFrame({'Date': future_dates, 'Predicted_Close': future_predictions_inv.flatten()})\n",
    "\n",
    "print(forecast_df.head())\n",
    "forecast_df.to_csv('silver_price_forecast_hybrid.csv', index=False)\n",
    "\n",
    "# Plot Forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index[-100:], df['Close'].tail(100), label='History')\n",
    "plt.plot(forecast_df['Date'], forecast_df['Predicted_Close'], label='Forecast', linestyle='--')\n",
    "plt.title(f'Silver Price Forecast (Next {FORECAST_DAYS} Days)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-grib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
